{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Part 5: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.3\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.2.2\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/chapter-overview.webp\" width=820px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946c3e56-b04b-4b0f-b35f-b485ce5b28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to prevent certain cells from being executed twice\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "executed_cells = set()\n",
    "\n",
    "@register_line_cell_magic\n",
    "def run_once(line, cell):\n",
    "    if line not in executed_cells:\n",
    "        get_ipython().run_cell(cell)\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 5.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 5.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%run_once balance_df\n",
    "\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "%%run_once label_mapping\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 5.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 5.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../../gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: ../../gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: ../../gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: ../../gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../../gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../../gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../../gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"../../gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward, but you must be careful. You must not let your guard down\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 5.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 1024)\n",
      "  (pos_emb): Embedding(1024, 1024)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (12): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (13): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (14): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (15): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (16): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (17): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (18): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (19): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (20): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (21): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (22): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (23): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-3.7743,  0.5238],\n",
      "         [-7.7890,  1.5769],\n",
      "         [-4.9057,  1.3229],\n",
      "         [-3.6375,  1.0749]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.6375,  1.0749]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 5.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.6375,  1.0749]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.894\n",
      "Validation loss: 0.919\n",
      "Test loss: 0.857\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 5.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.839, Val loss 0.901\n",
      "Ep 1 (Step 000050): Train loss 0.672, Val loss 0.662\n",
      "Ep 1 (Step 000100): Train loss 0.624, Val loss 0.639\n",
      "Training accuracy: 82.50% | Validation accuracy: 75.00%\n",
      "Ep 2 (Step 000150): Train loss 0.652, Val loss 0.634\n",
      "Ep 2 (Step 000200): Train loss 0.598, Val loss 0.594\n",
      "Ep 2 (Step 000250): Train loss 0.573, Val loss 0.576\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.543, Val loss 0.555\n",
      "Ep 3 (Step 000350): Train loss 0.512, Val loss 0.542\n",
      "Training accuracy: 85.00% | Validation accuracy: 82.50%\n",
      "Ep 4 (Step 000400): Train loss 0.417, Val loss 0.536\n",
      "Ep 4 (Step 000450): Train loss 0.492, Val loss 0.510\n",
      "Ep 4 (Step 000500): Train loss 0.502, Val loss 0.498\n",
      "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
      "Ep 5 (Step 000550): Train loss 0.477, Val loss 0.488\n",
      "Ep 5 (Step 000600): Train loss 0.525, Val loss 0.475\n",
      "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
      "Training completed in 1.78 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 84.52%\n",
      "Validation accuracy: 83.22%\n",
      "Test accuracy: 82.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 5.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_5/images/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../../gpt2/review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"../../gpt2/review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
